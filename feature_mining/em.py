import sys, os
import numpy as np
from scipy.sparse import csr_matrix


class EM:
    def __init__(self, dump_path = "../tests/data/em_01/"):
        self.max_iter = 50
        self.lambda_background = 0.7
        self.dist_threshold = 1e-6

        self.dump_path = dump_path
        self.reviews = np.load(self.dump_path + "Reviews.npy")
        self.hidden_parameters = np.load(self.dump_path + "HP.npy")
        self.hidden_parameters_background = np.load(self.dump_path + "HPB.npy")
        self.pi = np.load(self.dump_path + "PI.npy")
        self.topic_model = np.load(self.dump_path + 'TopicModel.npy').item()
        self.background_probability = np.load(self.dump_path + 'BackgroundProbability.npy').item()


    def em_e_step_dense(self):
        """
        E-Step of EM algo. Compute HP and BHP.

        Input:
            REVIEWS
            TOPIC MODEL
            PI (probability of choosing a FLM to generate a word)
            BACKGROUND PROBABILITY (BP) //scalar
            LAMBDA BACKGROUND (lambdaB) //scalar
            HP
            HPB

        Output:
            Updated HP
            Updated HPB

        Pseudo-code
        for each REVIEW (R):
            for each LINE in R (L):
                for each WORD in L (W):
                    - initialize sum of probabilities W in all topic models (S) to 0
                    - for each ASPECT in TOPIC_MODEL (A):
                        S += PI[R][L][A] * TOPIC_MODEL[A][W]
                        //prob. that line L of review R was generated by aspect A * prob. of word W in aspect A
                    - for each ASPECT in TOPIC_MODEL (A):
                        HP[R][L][W][A] = PI[R][L][A] * TOPIC_MODEL[A][W] / S
                        //compute prob that word W of line L (the "sentence") of review R is generated from aspect A
                    - HPB[R][L][W] = (lambdaB * BP[W]) / (lambdaB * BP[W] + ((1 - lambdaB) * S))
                        //compute ptob that word W of line L of review R generated from BLM

        :return:
        """
        for reviewNum in range(0, len(self.reviews)):
            for lineNum in range(0, len(self.reviews[reviewNum])):
                for word in self.reviews[reviewNum][lineNum]:
                    mysum = 0
                    for aspect in self.topic_model:
                        mysum += self.pi[reviewNum][lineNum][aspect] * self.topic_model[aspect][word]
                    for aspect in self.topic_model:
                        self.hidden_parameters[reviewNum][lineNum][word][aspect] = self.pi[reviewNum][lineNum][aspect] * self.topic_model[aspect][
                            word] / mysum

                        self.hidden_parameters_background[reviewNum][lineNum][word] = (self.lambda_background * self.background_probability[word]) / (self.lambda_background * self.background_probability[word] + ((1 - self.lambda_background) * mysum))

        np.save(self.dump_path + "MY_HP_Updated", self.hidden_parameters)
        np.save(self.dump_path + "MY_HPB_updated", self.hidden_parameters_background)

    def em_e_step_sparse(self):
        A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])
        v = np.array([1, 0, -1])
        A.dot(v)

        np.save(self.dump_path + "MY_HP_Updated", A)
        np.save(self.dump_path + "MY_HPB_updated", A)
        pass


if __name__ == '__main__':
    em = EM()
    em.em_e_step_dense()
