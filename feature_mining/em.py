import sys, os
import numpy as np
from scipy.sparse import csr_matrix


class EM:
    def __init__(self, dump_path = "../tests/data/em_01/"):
        self.dump_path = dump_path

        # Parameters for EM execution
        self.max_iter = 50
        self.lambda_background = 0.7
        self.dist_threshold = 1e-6

        # Parameters for Data size evaluation
        self.m = 0
        self.nw = 0
        self.na = 0

        # Parameters for EM internals
        self.reviews = np.load(self.dump_path + "Reviews.npy")
        self.hidden_parameters = np.load(self.dump_path + "HP.npy")
        self.hidden_parameters_background = np.load(self.dump_path + "HPB.npy")
        self.pi = np.load(self.dump_path + "PI.npy")
        self.topic_model = np.load(self.dump_path + 'TopicModel.npy').item()
        self.background_probability = np.load(self.dump_path + 'BackgroundProbability.npy').item()

        # Temporary parameters for matrix testing
        # TODO: update original parameters for this usage
        self.aspects_map = {}
        self.words_map = {}
        self.reviews_matrix = np.array([])
        self.pi_matrix = np.array([])
        self.topic_model_matrix = ()

    def em_e_step_dense(self):
        """
        E-Step of EM algo, as implemented by ***Santu***.
        Compute HP and BHP.

        Input:
            REVIEWS
            TOPIC MODEL
            PI (probability of choosing a FLM to generate a word)
            BACKGROUND PROBABILITY (BP) //scalar
            LAMBDA BACKGROUND (lambdaB) //scalar
            HP
            HPB

        Output:
            Updated HP
            Updated HPB

        Pseudo-code
        for each REVIEW (R):
            for each LINE in R (L):
                for each WORD in L (W):
                    - initialize sum of probabilities W in all topic models (S) to 0
                    - for each ASPECT in TOPIC_MODEL (A):
                        S += PI[R][L][A] * TOPIC_MODEL[A][W]
                        //prob. that line L of review R was generated by aspect A * prob. of word W in aspect A
                    - for each ASPECT in TOPIC_MODEL (A):
                        HP[R][L][W][A] = PI[R][L][A] * TOPIC_MODEL[A][W] / S
                        //compute prob that word W of line L (the "sentence") of review R is generated from aspect A
                    - HPB[R][L][W] = (lambdaB * BP[W]) / (lambdaB * BP[W] + ((1 - lambdaB) * S))
                        //compute ptob that word W of line L of review R generated from BLM

        :return:
        """
        for reviewNum in range(0, len(self.reviews)):
            for lineNum in range(0, len(self.reviews[reviewNum])):
                for word in self.reviews[reviewNum][lineNum]:
                    mysum = 0
                    for aspect in self.topic_model:
                        mysum += self.pi[reviewNum][lineNum][aspect] * self.topic_model[aspect][word]
                    for aspect in self.topic_model:
                        self.hidden_parameters[reviewNum][lineNum][word][aspect] = self.pi[reviewNum][lineNum][aspect] * self.topic_model[aspect][
                            word] / mysum

                        self.hidden_parameters_background[reviewNum][lineNum][word] = (self.lambda_background * self.background_probability[word]) / (self.lambda_background * self.background_probability[word] + ((1 - self.lambda_background) * mysum))

        np.save(self.dump_path + "MY_HP_Updated", self.hidden_parameters)
        np.save(self.dump_path + "MY_HPB_updated", self.hidden_parameters_background)

    def em_prepare_data_for_testing(self):
        """
        Prepare data for testing vectorised solution.
        Want to convert the photo of Santu's data for vectorised needs.
        :return:
        """
        m = 0   # number of sentences (lines) in all reviews - 8799
        nw = 0  # number of words in vocabulary - 7266
        na = 0  # number of aspects - 9

        for reviewNum in range(0, len(self.reviews)):
            for lineNum in range(0, len(self.reviews[reviewNum])):
                m += 1
        for aspect in self.topic_model:
            na += 1

        words_dict = {}
        for aspect in self.topic_model.keys():
            print(aspect, len(self.topic_model[aspect]))
            for word in self.topic_model[aspect]:
                words_dict[word] = True
        nw = len(words_dict.keys()) # 7266
        word_list = sorted(words_dict.keys())
        words_map = {}
        for word_id in range(0, len(word_list)):
            words_map[word_list[word_id]] = word_id

        print("m", "nw", "na")
        print(m, nw, na)

        # initialize reviews with zeros
        reviews_matrix = np.zeros(m * nw).reshape(m, nw)

        # construct the review matrix with count values for each words
        section_id = 0
        for reviewNum in range(0, len(self.reviews)):
            for lineNum in range(0, len(self.reviews[reviewNum])):
                for word in self.reviews[reviewNum][lineNum]:
                    reviews_matrix[section_id][words_map[word]] = self.reviews[reviewNum][lineNum][word]
                section_id += 1
        print("number of sections")
        print(section_id)

        # check first line
        for i in range(0, len(reviews_matrix[0])):
            if reviews_matrix[0][i] != 0:
                print(i, reviews_matrix[0][i], word_list[i])

        # construct the aspect map
        current_aspect = 0
        aspects_map = {}
        for one_aspect in sorted(self.pi[0][0].keys()):
            aspects_map[one_aspect] = current_aspect
            current_aspect += 1

        # initialize pi with zeros
        # pi_matrix = np.random.dirichlet(np.ones(m), na).transpose()
        pi_matrix = np.zeros(m * na).reshape(m, na)
        section_id = 0
        pi_matrix = np.zeros(m * na).reshape(m, na)
        for reviewNum in range(0, len(self.reviews)):
            for lineNum in range(0, len(self.reviews[reviewNum])):
                for aspect in self.pi[reviewNum][lineNum]:
                    pi_matrix[section_id][aspects_map[aspect]] = self.pi[reviewNum][lineNum][aspect]
                section_id += 1

        # initialize topic model with zeros
        topic_model_matrix = np.zeros(nw * na).reshape(nw, na)
        for aspect in self.topic_model:
            for word in self.topic_model[aspect]:
                topic_model_matrix[words_map[word]][aspects_map[aspect]] = self.topic_model[aspect][word]

        # update class parameters with matrices
        # TODO: clean this up to use only one set of input data
        self.reviews_matrix = reviews_matrix
        self.topic_model_matrix = topic_model_matrix
        self.pi_matrix = pi_matrix
        self.m = m
        self.nw = nw
        self.na = na
        self.aspects_map = aspects_map
        self.words_map = words_map
        self.words_list = word_list

    def em_prepare_data_for_testing_dummy(self):
        self.m = 2
        self.nw = 3
        self.na = 4

        self.reviews_matrix = np.random.randint(0, 2, self.m * self.nw).reshape(self.m, self.nw)
        self.topic_model = np.random.random(self.nw * self.na).reshape(self.nw, self.na)
        self.pi_matrix = np.random.dirichlet(np.ones(self.na), self.m)

    def em_e_step_sparse(self):
        """
        Vectorised E-step of EM.
        Needs intensive testing, at this stage.

        :return:
        """
        # Notation:
        # nw = number of words in vocabulary
        # m  = number of sentences (lines) in all reviews
        # na = number of aspects

        m   = self.m # 2 # number of sentences (lines) in all reviews
        nw  = self.nw # 3 # number of words in vocabulary
        na  = self.na #4 # number of aspects

        #Initialize reviews matrix:
        #Sentence/Word | word 1 ... ... ... ... word nw
        #---------------------------------------------------
        #Sentence 1    | count(s_1,w_1) ... ...  count(s_1, w_nw)
        #Sentence 2    | count(s_2,w_2) ... ...  count(s_2, w_nw)
        #...    ...     ... ...     ...     ...     ...
        #Sentence m    | count(s_m, w_1)... ...  count(s_m, w_nw)

        # random review
        # reviews = csr_matrix(np.random.randint(0, 3, m * nw).reshape(m, nw))
        reviews = self.reviews_matrix # np.random.randint(0, 2, m * nw).reshape(m, nw)
        print("reviews")
        print(reviews)

        # Compute binary reviews matrix (1 if word in sentence, 0 if not) (same dimensions as reviews)
        reviews_binary = np.where(reviews > 0, 1, 0)
        print("reviews_binary")
        print(reviews_binary)

        # Compute sparse matrix
        reviews = csr_matrix(reviews)
        reviews_binary = csr_matrix(reviews_binary)

        #Initialize topic model
        #Word/Aspect    | aspect 1   ...     ...     aspect na
        #-----------------------------------------------------
        #word 1         | tm(w1,a1) ...      ...    tm(w1, a_na)
        #...        ...             ....            ...     ...
        #word nw        | tm(w_nw, a_na) ... ....   tm(w_na, a_na)

        # random topic model
        # topic_model = csr_matrix(np.random.randint(0, 3, nw * na).reshape(nw, na))
        topic_model = self.topic_model_matrix # np.random.random(nw * na).reshape(nw, na)
        print("topic_model")
        print(topic_model)

        #Initialize pi
        #Sentence/Aspect | aspect 1 ...      ...    aspect na
        #-----------------------------------------------------
        #Sentence 1      | pi(s1,a1)  ...   ...     pi(s1, a_na)
        # ...        ...             ....            ...     ...
        #Sentence m      | pi(sm,a1)  ...   ...     pi(sm, a_na)
        #TODO:::: REDO HERE!!! Sum of probabilities of all aspects for a sentence should be 1!
        pi = self.pi_matrix # np.random.dirichlet(np.ones(na), m)
        print("pi")
        print(pi)
        print("sum of pi for each sentence")
        print(pi.sum(axis=1))

        #Initialize hidden_parameters FOR ONE SENTENCE
        #Sentence/Word | word 1 ... ... ... ... word nw
        #---------------------------------------------------
        #Sentence 1    | 0.0        ...     ...   0.0
        #Sentence 2    | 0.0    ...         ...   0.0
        #...    ...     ... ...     ...     ...   ...
        #Sentence m    | 0.0 ...             ...  0.0
        hidden_parameters = []
        hidden_parameters_one_sentence = np.zeros(m * nw).reshape(m, nw)
        for sentence in range(0, m):
            hidden_parameters.append(hidden_parameters_one_sentence)

        print("hidden_parameters")
        print(hidden_parameters[0])

        #TODO: treat multiple sentences
        # Compute topic model for sentence as review_binary[sentence_s]^T * topic_model
        sentence = 0
        # topic_model_sentence = reviews_binary.T[:,sentence].reshape(nw,1) * topic_model -- method with dummy data
        topic_model_sentence = reviews_binary[sentence].reshape(nw,1).multiply(topic_model)
        print("topic_model_sentence: " + str(sentence))
        print(topic_model_sentence)

        # Compute sum of review * topic_model for sentence_s
        # sentence_sum = pi[sentence].reshape(1,na).dot(topic_model_sentence.transpose()) -- method with dummy data
        sentence_sum = topic_model_sentence.dot(pi[sentence])
        print("snp.where(sentence_sum > 0)")
        print(np.where(sentence_sum > 0))

        # We will have 0 values for sentence_sum, for missing words
        # To avoid division by 0, sentence_sum(word) = 1
        sentence_sum = np.where(sentence_sum == 0, 1, sentence_sum)
        print("np.where(sentence_sum < 1), identity for multiplication/division")
        print(np.where(sentence_sum < 1)) # only computed sums

        # Compute hidden_parameters for sentence_s
        # hidden_parameters_sentence = (topic_model_sentence * pi[sentence]).transpose() / sentence_sum -- method with dummy data
        hidden_parameters_sentence = ((topic_model_sentence.multiply(pi[sentence])).T / sentence_sum).T # TODO: not optimal! Redox!
        print("hidden_parameters_sentence")
        print(hidden_parameters_sentence)

        '''
for i in np.where(reviews[sentence].todense() > 0)[1]:
    print(em.aspects_map.keys())
    print(word_list[i], hidden_parameters_sentence[i])
        
dict_keys(['battery', 'button', 'headphones', 'price', 'screen', 'size', 'software', 'sound', 'storage'])
GB [[0.16279447 0.0025804  0.03944819 0.11466597 0.16928515 0.00958067
  0.04880046 0.25526435 0.19758034]]
dict_keys(['battery', 'button', 'headphones', 'price', 'screen', 'size', 'software', 'sound', 'storage'])
I [[0.12705447 0.00610031 0.05580781 0.05934721 0.27663855 0.00689146
  0.06640865 0.26729379 0.13445776]]
dict_keys(['battery', 'button', 'headphones', 'price', 'screen', 'size', 'software', 'sound', 'storage'])
Nano [[0.14939639 0.0019929  0.05861404 0.07553192 0.31078625 0.0084954
  0.07674186 0.18892766 0.1295136 ]]
dict_keys(['battery', 'button', 'headphones', 'price', 'screen', 'size', 'software', 'sound', 'storage'])
iPod [[0.1291257  0.0053575  0.05385322 0.06656985 0.27662866 0.00542618
  0.06980449 0.26575351 0.12748088]]
dict_keys(['battery', 'button', 'headphones', 'price', 'screen', 'size', 'software', 'sound', 'storage'])
pleased [[0.05185843 0.00653626 0.02874464 0.13352919 0.12335271 0.00327903
  0.03555934 0.53306191 0.08407848]]
dict_keys(['battery', 'button', 'headphones', 'price', 'screen', 'size', 'software', 'sound', 'storage'])
purchase [[0.13109168 0.00234177 0.05286881 0.05004636 0.22687744 0.00603098
  0.04596653 0.37609063 0.1086858 ]]
  
  
###santu's first iteration, on em_sentence
 for key in updatedhp[0][0]:
    print(key, updatedhp[0][0][key])
    
I {'sound': 0.2672937858438519, 'battery': 0.1270544678597472, 'screen': 0.27663855251249303, 'headphones': 0.05580780692718888, 'software': 0.0664086462933959, 'size': 0.006891456151221802, 'price': 0.059347212652911964, 'storage': 0.13445775908871987, 'button': 0.00610031267046968}
pleased {'sound': 0.5330619072767221, 'battery': 0.0518584319923281, 'screen': 0.12335271465749757, 'headphones': 0.028744642221866675, 'software': 0.03555934483644542, 'size': 0.0032790289679597907, 'price': 0.13352919112632508, 'storage': 0.08407847762705724, 'button': 0.006536261293797957}
GB {'sound': 0.2552643520896477, 'battery': 0.16279447111752765, 'screen': 0.1692851518005996, 'headphones': 0.039448188355592544, 'software': 0.04880045895448517, 'size': 0.009580672874032383, 'price': 0.11466596993259483, 'storage': 0.19758033730645586, 'button': 0.0025803975690643134}
iPod {'sound': 0.26575351104834527, 'battery': 0.12912569762197348, 'screen': 0.2766286607090805, 'headphones': 0.05385322481564878, 'software': 0.06980449453972293, 'size': 0.005426176256144518, 'price': 0.06656985030229348, 'storage': 0.1274808823649425, 'button': 0.005357502341848541}
Nano {'sound': 0.18892765645559806, 'battery': 0.14939638521093326, 'screen': 0.3107862473019515, 'headphones': 0.05861403696637266, 'software': 0.07674185652674255, 'size': 0.00849540030815739, 'price': 0.07553192435225868, 'storage': 0.12951359500872292, 'button': 0.001992897869262857}
purchase {'sound': 0.37609063454881636, 'battery': 0.1310916790527423, 'screen': 0.22687744132514928, 'headphones': 0.052868807121202475, 'software': 0.04596652913076301, 'size': 0.006030979572256577, 'price': 0.050046355875500846, 'storage': 0.10868579859641375, 'button': 0.002341774777155295}
 
  '''

        # TODO: Compute hidden_parameters_background
        hidden_parameters_background = ['todo']

        # Example on sparse dot product
        np.save(self.dump_path + "MY_HP_Updated", hidden_parameters)
        np.save(self.dump_path + "MY_HPB_updated", hidden_parameters)


if __name__ == '__main__':
    em = EM()
    em.em_prepare_data_for_testing()
    # em.em_e_step_dense()
    em.em_e_step_sparse()
