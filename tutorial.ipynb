{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: GFLM for implicit feature detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This tutorial will guide you through the usage of the feature_mining package.\n",
    "It contains two parts:\n",
    "* quick start guide, using the default workflow; this should be enough to get you started\n",
    "* a more detailed step-by-step guide, if you want to fine-tune some of the parameters\n",
    "\n",
    "## Goal\n",
    "#### Given the following:\n",
    "* a text dataset\n",
    "* a set of predefined features\n",
    "\n",
    "#### Compute the following:\n",
    "* mapping of explicit and implicit features on the data\n",
    "* using both gflm_word and gflm_section algorithms\n",
    "\n",
    "## Naming conventions\n",
    "We will use the folowwing naming conventions:\n",
    "* section = one line of the reviews data; roughly equivalent to one sentence\n",
    "* pm = ParseAndModel module\n",
    "* em = Expectation Maximization module\n",
    "* gflm = Generative Feature Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Quick start guide\n",
    "Use this to jump right in detecting implicit features in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import the module and instantiate a FeatureMining object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_mining\n",
    "fm = feature_mining.FeatureMining()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load the demo files\n",
    "The package comes with a demo data set, based on iPod reviews.\n",
    "We have already initialized a **default set of features** which will be mapped on each section of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:>loading file:/Users/nfreundl/Documents/UIUC/CS410-TextInfoSys/CS410_CourseProject/feature_mining/data/iPod.final\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded features:  ['sound', 'battery', ['screen', 'display']]\n",
      "loaded dataset: ipod\n"
     ]
    }
   ],
   "source": [
    "# Load default dataset with default feature set\n",
    "fm.load_ipod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Execute Expectation-Maximization on iPod dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmVectorByFeature - base init...\n",
      "EmVectorByFeature - base loop...\n",
      "Maximum iterations reached\n",
      "Elapsed: 0.1806 seconds\n"
     ]
    }
   ],
   "source": [
    "## Executes Expectation-Maximization on previously loaded data.\n",
    "fm.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Compute feature mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Inspect the results\n",
    "* **gflm_word** and **gflm_section** are the values computed by gflm\n",
    "* **section_id** is the section to which the value refers (the sentence)\n",
    "* **implicit_feature_id** is the feature detected in the section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gflm_word  section_id  implicit_feature_id\n",
      "0   0.473993           3                    0\n",
      "1   0.479150           5                    0\n",
      "2   0.820335          12                    0\n",
      "3   0.650862          22                    0\n",
      "4   0.478575          24                    0\n",
      "5   0.650862          26                    0\n",
      "6   0.377785          31                    0\n",
      "7   0.431461          36                    0\n",
      "8   0.395499          40                    0\n",
      "9   0.384849          47                    0\n",
      "     gflm_section  section_id  implicit_feature_id\n",
      "312      1.000000         163                    2\n",
      "313      0.988007         164                    2\n",
      "314      0.644163         185                    2\n",
      "315      0.491794         197                    2\n",
      "316      0.488347         206                    2\n",
      "317      0.498592         218                    2\n",
      "318      0.502981         223                    2\n",
      "319      0.999993         250                    2\n",
      "320      0.425549         261                    2\n",
      "321      0.939746         274                    2\n"
     ]
    }
   ],
   "source": [
    "print(fm.gflm.gflm_word.head(10))\n",
    "print(fm.gflm.gflm_section.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Detailed guide\n",
    "Use this procedure if you want to know more about the internal workings of the project, or if you wish to fine-tune some of its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import feature_mining module.\n",
    "Import ParseAndModel.\n",
    "\"\"\"\n",
    "import feature_mining\n",
    "from feature_mining import ParseAndModel\n",
    "from feature_mining import EmVectorByFeature\n",
    "from feature_mining import GFLM\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load the demo files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_background', 'model_feature', 'section_word_counts_matrix', 'model_background_matrix', 'model_feature_matrix', 'vocabulary_lookup'])\n"
     ]
    }
   ],
   "source": [
    "# Create a model based on a predefined list of features and an input data file.\n",
    "import pkg_resources\n",
    "filename = pkg_resources.resource_filename('feature_mining', 'data/iPod.final')\n",
    "feature_list=[\"sound\", \"battery\", [\"screen\", \"display\"]]\n",
    "\n",
    "pm = ParseAndModel(feature_list=feature_list,   # list of features\n",
    "                   filename = filename,         # file with input data\n",
    "                   nlines=100)                  # number of lines to read\n",
    "\n",
    "print(pm.model_results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_background', 'model_feature', 'section_word_counts_matrix', 'model_background_matrix', 'model_feature_matrix', 'vocabulary_lookup'])\n",
      "Model background\n",
      "[0.004310344827586207,\n",
      " 0.004310344827586207,\n",
      " 0.01293103448275862,\n",
      " 0.05603448275862069,\n",
      " 0.023706896551724137,\n",
      " 0.0021551724137931034,\n",
      " 0.017241379310344827]\n",
      "Feature model\n",
      "[0.0035684588810039313, 0.0035684588810039313]\n",
      "Section word counts matrix (sentence/line) - sparse\n",
      "<1x258 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>\n",
      "Background model matrix - sparse\n",
      "<1x258 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 258 stored elements in Compressed Sparse Row format>\n",
      "Feature model matrix\n",
      "array([[0.00356846, 0.00336429, 0.00363519],\n",
      "       [0.00356846, 0.00336429, 0.00363519]])\n",
      "Vocabulary words\n",
      "'pleased'\n"
     ]
    }
   ],
   "source": [
    "# Keys in the model dictionary\n",
    "print(pm.model_results.keys())\n",
    "\n",
    "# Language background model\n",
    "print(\"Model background\")\n",
    "pprint(pm.model_results['model_background'][0:7])\n",
    "\n",
    "# Feature model\n",
    "print(\"Feature model\")\n",
    "pprint(pm.model_results['model_feature'][0][0:2])\n",
    "\n",
    "# Word counts per section matrix (sentence/line)\n",
    "print(\"Section word counts matrix (sentence/line) - sparse\")\n",
    "pprint(pm.model_results['section_word_counts_matrix'][0][0:2])\n",
    "\n",
    "# Background model matrix - sparse\n",
    "print(\"Background model matrix - sparse\")\n",
    "pprint(pm.model_results['model_background_matrix'][0][0:2])\n",
    "\n",
    "# Feature model matrix\n",
    "print(\"Feature model matrix\")\n",
    "pprint(pm.model_results['model_feature_matrix'][0:2][0:])\n",
    "\n",
    "# Vocabulary words\n",
    "print(\"Vocabulary words\")\n",
    "pprint(pm.model_results['vocabulary_lookup'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Launch Expectation Maximization on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling EMVectorByFeature\n",
      "EmVectorByFeature - base init...\n",
      "EmVectorByFeature - base loop...\n",
      "Maximum iterations reached\n",
      "Elapsed: 0.1029 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Calling EMVectorByFeature\")\n",
    "em = EmVectorByFeature(explicit_model=pm,\n",
    "                       max_iter=30)\n",
    "em.em()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Compute GFLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gflm_word  section_id  implicit_feature_id\n",
      "0    0.748721          12                    0\n",
      "1    0.653669          22                    0\n",
      "2    0.569295          26                    0\n",
      "3    0.351849          57                    0\n",
      "4    0.375870          81                    0\n",
      "5    0.386211          89                    0\n",
      "6    0.553966          11                    1\n",
      "7    0.737475          13                    1\n",
      "8    0.737475          14                    1\n",
      "9    0.433130          18                    1\n",
      "10   0.434692          19                    1\n",
      "11   0.400792          37                    1\n",
      "12   0.400459          43                    1\n",
      "13   0.554363          44                    1\n",
      "14   0.457476          50                    1\n",
      "15   0.737475          88                    1\n",
      "16   0.394000           1                    2\n",
      "17   0.354486           3                    2\n",
      "18   0.378213           7                    2\n",
      "19   0.394486          10                    2\n",
      "    gflm_section  section_id  implicit_feature_id\n",
      "0       0.528208           2                    0\n",
      "1       0.608378           6                    0\n",
      "2       0.397680           8                    0\n",
      "3       1.000000          12                    0\n",
      "4       0.490453          17                    0\n",
      "5       0.682029          21                    0\n",
      "6       1.000000          22                    0\n",
      "7       1.000000          26                    0\n",
      "8       0.404558          30                    0\n",
      "9       0.829624          33                    0\n",
      "10      0.476913          35                    0\n",
      "11      0.496256          36                    0\n",
      "12      0.670631          38                    0\n",
      "13      0.603230          40                    0\n",
      "14      0.498276          42                    0\n",
      "15      0.354178          49                    0\n",
      "16      0.608321          53                    0\n",
      "17      0.585720          56                    0\n",
      "18      0.857721          57                    0\n",
      "19      0.574451          58                    0\n"
     ]
    }
   ],
   "source": [
    "gflm = GFLM(em_results=em, section_threshold=0.35, word_threshold=0.35)\n",
    "gflm.calc_gflm_section()\n",
    "gflm.calc_gflm_word()\n",
    "\n",
    "print(gflm.gflm_word.head(20))\n",
    "print(gflm.gflm_section.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
